{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain \n",
    "from glob import glob\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import pandas as pd\n",
    "import io\n",
    "import nltk\n",
    "import math\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"as a user, you can chat with haybot's artificial intelligence chatbot. as a user, you can connect and chat with other users from the target foreign language you want to learn. as a user, you can play a guessing mini game on the hayword feature. as a user, you can check, activate or deactivate premium feature functions. as a user, you can use the phrase ideas and topic ideas in haybot and hayfriend. as a user, you can activate bot audio replies and get a voice response from the bot. as a user, you can translate various words with haylingo's word-by-word translation feature. as a user, you can do text-to-speech conversions while talking.\"]\n"
     ]
    }
   ],
   "source": [
    "#LowerCase FR\n",
    "file = open('FR_beforecase.txt', 'r') #BeforeCase\n",
    "\n",
    "lines = [line.lower() for line in file]\n",
    "with open('FR_aftercase.txt', 'w') as out: #AfterCase\n",
    "    out.writelines(sorted(lines))\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"actor user sets the language when first logging into the haylingo chatbot. the system stores the origin language of the actor user and adjusts the language in the application such as the actor user's home language and sets the artificial intelligence language of the haybot feature and other target users according to the target language being studied. actor users who have entered the main page of the haylingo application will be given an option to be able to view other main features such as haybot, hayfriend, and hayword as well. actor user has seen the menu list display and the menu list displays several feature menus that can be selected and wants to see a help list that can help if the user needs certain assistance in the chatbot. actor users have seen the menu list display and the list menu displays several feature menus that can be selected, including a menu to change the language in the settings where there is a button to change the language. actor users have seen the menu list display and the list menu displays several feature menus that can be selected, including the settings menu card with buttons to view premium profiles and status. the actor user has seen the menu list display and the menu list displays several feature menus that can be selected, including the main menu which contains the haybot feature. this feature has a talkative chatbot function to be able to talk or talk to the user. the actor user enters the haybot menu and starts chatting with the haybot chatbot. actor users have seen the menu list display and the list menu displays several feature menus that can be selected, including the main menu which includes the hayfriend feature. this feature has a function to bring together actor users with other users who are studying the same language to be able to talk and/or learn to better understand certain languages according to the target language they want to learn (currently only english). the actor user has seen the menu list display and the list menu displays several feature menus that can be selected, including the main menu which contains the hayword feature. this feature has a function as a feature that can help increase vocabulary and find some unique words that were previously unknown to the user through a 'guess word' game scheme. the user actor when entering this feature is faced with a word which the user has to guess whether the word is included in a certain word setting (such as verb, noun, adjective).\"]\n"
     ]
    }
   ],
   "source": [
    "#LowerCase Use Case Scenario (Description) UCD\n",
    "file = open('UCD_beforecase.txt', 'r') #BeforeCase\n",
    "\n",
    "lines = [line.lower() for line in file]\n",
    "with open('UCD_aftercase.txt', 'w') as out: #AfterCase\n",
    "    out.writelines(sorted(lines))\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FR And UCD Documentation\n",
    "d1 = \"as a user, you can chat with haybot's artificial intelligence chatbot.\"\n",
    "d2 = \"as a user, you can connect and chat with other users from the target foreign language you want to learn.\"\n",
    "d3 = \"as a user, you can play this game, guess the word on the hayword feature.\"\n",
    "d4 = \"as a user, you can check, activate or deactivate premium feature functions.\"\n",
    "d5 = \"as a user, you can use the phrase ideas and topic ideas in haybot and hayfriend.\"\n",
    "d6 = \"as a user, you can activate bot audio replies and get a voice response from the bot.\"\n",
    "d7 = \"as a user, you can translate various words with haylingo's word-by-word translation feature.\"\n",
    "d8 = \"as a user, you can do text-to-speech conversions while talking.\"\n",
    "d9 = \"Actor user sets the language when first logging into the HayLingo chatbot. The system stores the origin language of the actor user and adjusts the language in the application such as the actor user's home language and sets the artificial intelligence language of the HayBot feature and other target users according to the target language being studied.\"\n",
    "d10 = \"Actor users who have entered the main page of the HayLingo application will be given an option to be able to view other main features such as HayBot, HayFriend, and HayWord as well.\"\n",
    "d11 = \"Actor user has seen the menu list display and the menu list displays several feature menus that can be selected and wants to see a help list that can help if the user needs certain assistance in the chatbot.\"\n",
    "d12 = \"Actor users have seen the menu list display and the list menu displays several feature menus that can be selected, including a menu to change the language in the settings where there is a button to change the language.\"\n",
    "d13 = \"Actor users have seen the menu list display and the list menu displays several feature menus that can be selected, including the settings menu card with buttons to view premium profiles and status.\"\n",
    "d14 = \"Actor user has seen the menu list display and the menu list displays several feature menus that can be selected, including the main menu which contains the HayBot feature. This feature has a talkative chatbot function to be able to talk or talk to the user. The actor user enters the HayBot menu and starts chatting with the HayBot chatbot.\"\n",
    "d15 = \"Actor users have seen the menu list display and the list menu displays several feature menus that can be selected, including the main menu which includes the HayFriend feature. This feature has a function to bring together actor users with other users who are studying the same language to be able to talk and/or learn to better understand certain languages according to the target language they want to learn (currently only English).\"\n",
    "d16 = \"Actor user has seen the menu list display and the list menu displays several feature menus that can be selected, including the main menu which contains the HayWord feature. This feature has a function as a feature that can help increase vocabulary and find some unique words that were previously unknown to the user through a 'guess word' game scheme. The user actor when entering this feature is faced with a word which the user has to guess whether the word is included in a certain word setting (such as verb, noun, adjective).\"\n",
    "FR_dataset = [d1,d2,d3,d4,d5,d6,d7,d8]\n",
    "UCD_dataset = [d9,d10,d11,d12,d13,d14,d15,d16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user': 38, ',': 1, 'chat': 7, 'haybot': 18, \"'s\": 0, 'artificial': 4, 'intelligence': 23, 'chatbot': 8, '.': 2, 'connect': 10, 'users': 39, 'target': 32, 'foreign': 14, 'language': 24, 'want': 42, 'learn': 25, 'play': 27, 'game': 16, 'guess': 17, 'word': 43, 'hayword': 21, 'feature': 13, 'check': 9, 'activate': 3, 'deactivate': 12, 'premium': 28, 'functions': 15, 'use': 37, 'phrase': 26, 'ideas': 22, 'topic': 34, 'hayfriend': 19, 'bot': 6, 'audio': 5, 'replies': 29, 'voice': 41, 'response': 30, 'translate': 35, 'various': 40, 'words': 45, 'haylingo': 20, 'word-by-word': 44, 'translation': 36, 'text-to-speech': 33, 'conversions': 11, 'talking': 31}\n"
     ]
    }
   ],
   "source": [
    "#Tokenization, Stop Words, Steaming FR\n",
    "LemDocuments = CountVectorizer(tokenizer=word_tokenize, stop_words='english')\n",
    "LemDocuments.fit_transform(FR_dataset)\n",
    "print (LemDocuments.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'actor': 9, 'user': 84, 'sets': 70, 'language': 51, 'logging': 55, 'haylingo': 42, 'chatbot': 23, '.': 6, 'stores': 75, 'origin': 62, 'adjusts': 11, 'application': 13, \"'s\": 2, 'home': 45, 'artificial': 14, 'intelligence': 50, 'haybot': 40, 'feature': 34, 'target': 80, 'users': 85, 'according': 8, 'studied': 76, 'entered': 30, 'main': 56, 'page': 63, 'given': 38, 'option': 61, 'able': 7, 'view': 87, 'features': 35, ',': 5, 'hayfriend': 41, 'hayword': 43, 'seen': 68, 'menu': 57, 'list': 54, 'display': 27, 'displays': 28, 'menus': 58, 'selected': 69, 'wants': 90, 'help': 44, 'needs': 59, 'certain': 21, 'assistance': 15, 'including': 48, 'change': 22, 'settings': 72, 'button': 18, 'card': 20, 'buttons': 19, 'premium': 64, 'profiles': 66, 'status': 74, 'contains': 25, 'talkative': 79, 'function': 36, 'talk': 78, 'enters': 32, 'starts': 73, 'chatting': 24, 'includes': 47, 'bring': 17, 'studying': 77, 'and/or': 12, 'learn': 53, 'better': 16, 'understand': 81, 'languages': 52, 'want': 89, '(': 3, 'currently': 26, 'english': 29, ')': 4, 'increase': 49, 'vocabulary': 88, 'unique': 82, 'words': 92, 'previously': 65, 'unknown': 83, \"'guess\": 1, 'word': 91, \"'\": 0, 'game': 37, 'scheme': 67, 'entering': 31, 'faced': 33, 'guess': 39, 'included': 46, 'setting': 71, 'verb': 86, 'noun': 60, 'adjective': 10}\n"
     ]
    }
   ],
   "source": [
    "#Tokenization, Stop Words, Steaming UCD\n",
    "LemDocuments = CountVectorizer(tokenizer=word_tokenize, stop_words='english')\n",
    "LemDocuments.fit_transform(UCD_dataset)\n",
    "print (LemDocuments.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as a user , you can chat with haybot 's artifici intellig chatbot . \n",
      "as a user , you can connect and chat with other user from the target foreign languag you want to learn . \n",
      "as a user , you can play thi game , guess the word on the hayword featur . \n",
      "as a user , you can check , activ or deactiv premium featur function . \n",
      "as a user , you can use the phrase idea and topic idea in haybot and hayfriend . \n",
      "as a user , you can activ bot audio repli and get a voic respons from the bot . \n",
      "as a user , you can translat variou word with haylingo 's word-by-word translat featur . \n",
      "as a user , you can do text-to-speech convers while talk . \n"
     ]
    }
   ],
   "source": [
    "#Steaming FR\n",
    "def stemSentence(sentence):\n",
    "    token_words = word_tokenize(sentence)\n",
    "    token_words\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(porter.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)\n",
    "\n",
    "for i in range (len(FR_dataset)):\n",
    "    FR_dataset[i] = stemSentence(FR_dataset[i])\n",
    "    print (FR_dataset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actor user set the languag when first log into the haylingo chatbot . the system store the origin languag of the actor user and adjust the languag in the applic such as the actor user 's home languag and set the artifici intellig languag of the haybot featur and other target user accord to the target languag be studi . \n",
      "actor user who have enter the main page of the haylingo applic will be given an option to be abl to view other main featur such as haybot , hayfriend , and hayword as well . \n",
      "actor user ha seen the menu list display and the menu list display sever featur menu that can be select and want to see a help list that can help if the user need certain assist in the chatbot . \n",
      "actor user have seen the menu list display and the list menu display sever featur menu that can be select , includ a menu to chang the languag in the set where there is a button to chang the languag . \n",
      "actor user have seen the menu list display and the list menu display sever featur menu that can be select , includ the set menu card with button to view premium profil and statu . \n",
      "actor user ha seen the menu list display and the menu list display sever featur menu that can be select , includ the main menu which contain the haybot featur . thi featur ha a talk chatbot function to be abl to talk or talk to the user . the actor user enter the haybot menu and start chat with the haybot chatbot . \n",
      "actor user have seen the menu list display and the list menu display sever featur menu that can be select , includ the main menu which includ the hayfriend featur . thi featur ha a function to bring togeth actor user with other user who are studi the same languag to be abl to talk and/or learn to better understand certain languag accord to the target languag they want to learn ( current onli english ) . \n",
      "actor user ha seen the menu list display and the list menu display sever featur menu that can be select , includ the main menu which contain the hayword featur . thi featur ha a function as a featur that can help increas vocabulari and find some uniqu word that were previous unknown to the user through a 'guess word ' game scheme . the user actor when enter thi featur is face with a word which the user ha to guess whether the word is includ in a certain word set ( such as verb , noun , adject ) . \n"
     ]
    }
   ],
   "source": [
    "#Steaming UCD\n",
    "def stemSentence(sentence):\n",
    "    token_words = word_tokenize(sentence)\n",
    "    token_words\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(porter.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)\n",
    "\n",
    "for i in range (len(UCD_dataset)):\n",
    "    UCD_dataset[i] = stemSentence(UCD_dataset[i])\n",
    "    print (UCD_dataset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 1 0 0 0 2 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#Term Frequency (TF) FR\n",
    "tf_matrixFR = LemDocuments.transform(FR_dataset).toarray()\n",
    "print (tf_matrixFR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 93)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_matrixFR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0 0 0 2 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 2 0 0 0 4 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 2 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 2 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 3 0 0 3 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 4 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 4 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 3 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 2 0 0 0 0 0 0 0 0\n",
      "  1 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 1 5 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      "  0 0 0 0 0 0 3 0 0 0 0 0 3 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 1 1 2 0 0 2 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 2 0 1 0 0 0 0 0 0\n",
      "  1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 2 2 0 1 4 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      "  0 0 0 0 0 0 1 0 1 1 0 0 3 0 0 0 0 1 0 0 0]\n",
      " [1 1 0 1 1 3 3 0 0 2 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 2 0 0 0 0 0 0 0 0\n",
      "  1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 2 0 1 4 0 0 1 0 0 0 0 0 0 1 1 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 1 4 0 1 0 0 0 0 5 0]]\n"
     ]
    }
   ],
   "source": [
    "#Term Frequency (TF) UCD\n",
    "tf_matrixUCD = LemDocuments.transform(UCD_dataset).toarray()\n",
    "print (tf_matrixUCD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 93)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_matrixUCD.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.19722458 3.19722458 2.09861229 3.19722458 3.19722458 1.\n",
      " 1.         3.19722458 3.19722458 3.19722458 3.19722458 3.19722458\n",
      " 3.19722458 3.19722458 3.19722458 3.19722458 3.19722458 3.19722458\n",
      " 3.19722458 3.19722458 3.19722458 3.19722458 3.19722458 2.5040774\n",
      " 3.19722458 3.19722458 3.19722458 3.19722458 3.19722458 3.19722458\n",
      " 3.19722458 3.19722458 3.19722458 3.19722458 3.19722458 3.19722458\n",
      " 2.5040774  2.5040774  3.19722458 2.5040774  2.09861229 2.5040774\n",
      " 2.5040774  2.5040774  3.19722458 3.19722458 3.19722458 3.19722458\n",
      " 3.19722458 3.19722458 3.19722458 3.19722458 3.19722458 2.5040774\n",
      " 3.19722458 3.19722458 3.19722458 3.19722458 3.19722458 3.19722458\n",
      " 3.19722458 3.19722458 3.19722458 3.19722458 2.5040774  3.19722458\n",
      " 3.19722458 3.19722458 3.19722458 3.19722458 3.19722458 3.19722458\n",
      " 3.19722458 3.19722458 3.19722458 3.19722458 3.19722458 3.19722458\n",
      " 2.5040774  3.19722458 2.5040774  3.19722458 3.19722458 3.19722458\n",
      " 1.         3.19722458 3.19722458 3.19722458 3.19722458 2.5040774\n",
      " 3.19722458 2.09861229 3.19722458]\n"
     ]
    }
   ],
   "source": [
    "#Inverse Document Frequency (IDF) FR\n",
    "tfidfTranFR = TfidfTransformer(norm=\"l2\")\n",
    "tfidfTranFR.fit(tf_matrixFR)\n",
    "print (tfidfTranFR.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.5040774  2.5040774  2.5040774  2.09861229 2.09861229 1.25131443\n",
      " 1.         3.19722458 3.19722458 1.         3.19722458 3.19722458\n",
      " 2.5040774  3.19722458 3.19722458 3.19722458 2.5040774  2.5040774\n",
      " 2.09861229 3.19722458 2.5040774  1.81093022 3.19722458 1.81093022\n",
      " 3.19722458 3.19722458 3.19722458 1.25131443 3.19722458 2.5040774\n",
      " 3.19722458 3.19722458 3.19722458 3.19722458 3.19722458 3.19722458\n",
      " 1.81093022 2.5040774  2.5040774  2.5040774  1.81093022 2.09861229\n",
      " 2.09861229 2.09861229 2.09861229 2.5040774  3.19722458 3.19722458\n",
      " 3.19722458 3.19722458 3.19722458 3.19722458 3.19722458 2.5040774\n",
      " 1.25131443 3.19722458 1.58778666 1.25131443 3.19722458 3.19722458\n",
      " 2.5040774  2.5040774  2.5040774  2.5040774  2.5040774  3.19722458\n",
      " 3.19722458 2.5040774  1.25131443 3.19722458 3.19722458 3.19722458\n",
      " 3.19722458 3.19722458 3.19722458 3.19722458 3.19722458 3.19722458\n",
      " 2.09861229 3.19722458 2.09861229 2.5040774  3.19722458 2.5040774\n",
      " 1.         3.19722458 2.5040774  2.09861229 3.19722458 2.09861229\n",
      " 3.19722458 2.5040774  3.19722458]\n"
     ]
    }
   ],
   "source": [
    "#Inverse Document Frequency (IDF) UCD\n",
    "tfidfTranUCD = TfidfTransformer(norm=\"l2\")\n",
    "tfidfTranUCD.fit(tf_matrixUCD)\n",
    "print (tfidfTranUCD.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The idf for terms that appear in one document : 1.916290731874155\n",
      "The idf for terms that appear in two document : 1.5108256237659907\n",
      "The idf for terms that appear in three document : 1.2231435513142097\n"
     ]
    }
   ],
   "source": [
    "def idf(n,df):\n",
    "    result = math.log((n+1.0)/(df+1.0)) + 1\n",
    "    return result\n",
    "print (\"The idf for terms that appear in one document : \" + str(idf(4,1)))\n",
    "print (\"The idf for terms that appear in two document : \" + str(idf(4,2)))\n",
    "print (\"The idf for terms that appear in three document : \" + str(idf(4,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.49356915 0.         0.         0.23518834\n",
      "  0.23518834 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.58892981\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.49356915 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.23518834 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.20075946\n",
      "  0.20075946 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.50271723\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.50271723 0.         0.         0.\n",
      "  0.40151892 0.         0.         0.         0.         0.50271723\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.37001914\n",
      "  0.18500957 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.46327829 0.         0.46327829 0.         0.\n",
      "  0.         0.46327829 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.18500957 0.         0.         0.         0.         0.\n",
      "  0.         0.38826336 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.46447856\n",
      "  0.23223928 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.58154514 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.58154514 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.23223928 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.27042264\n",
      "  0.27042264 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.56751227 0.67715922\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.27042264 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.57735027\n",
      "  0.57735027 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.57735027 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.49356915 0.         0.         0.23518834\n",
      "  0.23518834 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.58892981 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.23518834 0.         0.         0.         0.         0.\n",
      "  0.         0.49356915 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.32843594\n",
      "  0.32843594 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.82242902 0.         0.         0.         0.         0.\n",
      "  0.32843594 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF Results FR\n",
    "tfidf_matrixFR = tfidfTranFR.transform(tf_matrixFR)\n",
    "print (tfidf_matrixFR.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.28650131 0.         0.         0.\n",
      "  0.22882784 0.         0.         0.34324176 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.20719562\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.20719562 0.\n",
      "  0.24011046 0.         0.         0.28650131 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.28650131 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.48022091 0.         0.         0.\n",
      "  0.45765567 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.32566335\n",
      "  0.1301285  0.         0.         0.1301285  0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.32585184 0.         0.23565364 0.27308928\n",
      "  0.27308928 0.27308928 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.4132326  0.         0.         0.\n",
      "  0.         0.32585184 0.         0.32585184 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.1301285  0.         0.         0.27308928 0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.11901985 0.         0.         0.11901985 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.21553665 0.         0.21553665\n",
      "  0.         0.         0.         0.29786252 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.49955306 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.44679378 0.         0.         0.44679378 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.14893126 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.23803971 0.         0.         0.         0.         0.24977653\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.18039636\n",
      "  0.14416549 0.         0.         0.14416549 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.30254746 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.36079271 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.36079271 0.         0.         0.72158542 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.18039636 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.14416549 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.1551353\n",
      "  0.12397787 0.         0.         0.12397787 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.26018149 0.         0.31045019 0.         0.         0.\n",
      "  0.         0.         0.         0.3102706  0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.3102706  0.         0.         0.62054121 0.         0.\n",
      "  0.         0.         0.         0.         0.31045019 0.\n",
      "  0.         0.         0.1551353  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.12397787 0.         0.         0.26018149 0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.09745198\n",
      "  0.23363908 0.         0.         0.15575939 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.28206938\n",
      "  0.         0.         0.         0.19490397 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.14103469 0.         0.         0.         0.42310407 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.19490397 0.         0.12365634 0.48725992 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.09745198 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.49031784 0.         0.         0.         0.         0.\n",
      "  0.23363908 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.17155172 0.17155172 0.10228909\n",
      "  0.16349063 0.         0.         0.16349063 0.         0.\n",
      "  0.20469659 0.         0.         0.         0.20469659 0.20469659\n",
      "  0.         0.         0.         0.14803506 0.         0.\n",
      "  0.         0.         0.         0.20457818 0.         0.20469659\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.14803506 0.         0.         0.         0.         0.17155172\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.40939318\n",
      "  0.20457818 0.         0.12979412 0.40915636 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.10228909 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.17155172 0.         0.17155172 0.20469659 0.         0.\n",
      "  0.24523594 0.         0.         0.         0.         0.17155172\n",
      "  0.         0.         0.        ]\n",
      " [0.14089729 0.14089729 0.         0.11808292 0.11808292 0.21122367\n",
      "  0.16880144 0.         0.         0.11253429 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.10189587 0.         0.\n",
      "  0.         0.         0.         0.14081578 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.10189587 0.14089729 0.         0.14089729 0.         0.\n",
      "  0.         0.11808292 0.11808292 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.14081578 0.         0.08934022 0.28163156 0.         0.\n",
      "  0.14089729 0.         0.         0.         0.         0.\n",
      "  0.         0.14089729 0.07040789 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.14089729\n",
      "  0.22506858 0.         0.14089729 0.         0.         0.\n",
      "  0.         0.70448644 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF Results UCD\n",
    "tfidf_matrixUCD = tfidfTranUCD.transform(tf_matrixUCD)\n",
    "print (tfidf_matrixUCD.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6  \\\n",
      "0  0.527150  0.471112  0.127006  0.159428  0.303227  0.396341  0.444269   \n",
      "1  0.254113  0.143754  0.295168  0.211706  0.477107  0.338281  0.298632   \n",
      "2  0.210912  0.245039  0.066059  0.082923  0.096557  0.206148  0.083976   \n",
      "3  0.110239  0.123044  0.120094  0.150752  0.126754  0.270620  0.110239   \n",
      "4  0.094802  0.105814  0.103277  0.310183  0.109005  0.232725  0.094802   \n",
      "5  0.507768  0.160280  0.122510  0.235803  0.392833  0.326047  0.132818   \n",
      "6  0.120185  0.530118  0.113467  0.228523  0.254358  0.295035  0.120185   \n",
      "7  0.142311  0.166663  0.609807  0.248838  0.163631  0.349351  0.490024   \n",
      "\n",
      "          7  \n",
      "0  0.225466  \n",
      "1  0.192437  \n",
      "2  0.117271  \n",
      "3  0.153947  \n",
      "4  0.132390  \n",
      "5  0.588729  \n",
      "6  0.308925  \n",
      "7  0.198735  \n"
     ]
    }
   ],
   "source": [
    "#Cosin Similarity\n",
    "cos_similarity_matrix = (tfidf_matrixUCD * tfidf_matrixFR.T).toarray()\n",
    "print (pd.DataFrame(cos_similarity_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2623925974884336"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "cohen_kappa_score(tf_matrixUCD[5], tf_matrixFR[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
